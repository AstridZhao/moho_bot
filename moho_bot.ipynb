{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/astridz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/astridz/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.epsilla.com/build-a-chatbot-that-runs-purely-on-your-local-machine-using-llama-2-epsilla-langchain-a5053b16f85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading(fileName):\n",
    "    f = open(fileName, \"r\")\n",
    "    content = f.read() \n",
    "    f.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing(input, filename):\n",
    "    f = open(filename, 'w')\n",
    "    f.write(input)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "web = \"https://www.mtholyoke.edu/academics/find-your-program/computer-science\"\n",
    "loader = WebBaseLoader(web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Epsilla Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these 2 commands to install the Epsilla vector database docker image on your personal computer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/epsilla-cloud/vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from epsilla/vectordb\n",
      "Digest: sha256:c4fbafa4a0055c3aa5750db7602ce507f894184d4fb769559296412b2a48f7b3\n",
      "Status: Image is up to date for epsilla/vectordb:latest\n",
      "docker.io/epsilla/vectordb:latest\n",
      "\u001b[1m\n",
      "What's Next?\n",
      "\u001b[0m  View a summary of image vulnerabilities and recommendations â†’ \u001b[36mdocker scout quickview epsilla/vectordb\u001b[0m\n",
      "latest: Pulling from epsilla/vectordb\n",
      "Digest: sha256:c4fbafa4a0055c3aa5750db7602ce507f894184d4fb769559296412b2a48f7b3\n",
      "Status: Image is up to date for epsilla/vectordb:latest\n",
      "c8574050567ae5045672fa4f985b1d44372a231067c35055f0c4af066ba46fb8\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint naughty_ishizaka (c27776ba064260427bdc0fc7245bbdd16b2da1ab0c03239418c32f5b7f1fc8a8): Bind for 0.0.0.0:8888 failed: port is already allocated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# docker installed in \"/Users/astridz/Documents/Moho_Bot/myvenv/lib/python3.10/site-packages/docker\"\n",
    "!docker pull epsilla/vectordb\n",
    "!docker run --pull=always -d -p 8888:8888 epsilla/vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize** the data_string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astridz/Documents/Moho_Bot/myvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/astridz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/astridz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import string\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, stopping, stemming):# Tokenize each document in the list\n",
    "    tokenized_documents = []\n",
    "    trans = str.maketrans('','', string.punctuation)\n",
    "    sentences = nltk.sent_tokenize(data)  # Tokenize the document into sentences\n",
    "    for each in sentences:\n",
    "            #Tokenization: remove punctuation\n",
    "            each = each.translate(trans)\n",
    "            #content clear\n",
    "            each = each.replace (\"\\n\", \" \")\n",
    "            #Case folding: make lowercase\n",
    "            each = each.lower()\n",
    "            words = [nltk.word_tokenize(each)]\n",
    "            # Tokenize each sentence into words\n",
    "            tokenized_documents.extend(words)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stoplist = set(stopwords.words('english'))\n",
    " \n",
    "    eachline = []\n",
    "    output = []\n",
    "    \n",
    "    for sentences in tokenized_documents:\n",
    "            #Stopping & Normalization option\n",
    "            if (stopping == True):\n",
    "                filtered_stop = [word for word in sentences if word not in stoplist]\n",
    "                if (stemming == True):\n",
    "                    stem_words = filtered_stop\n",
    "                    stem_words  = [stemmer.stem(w) for w in stem_words]\n",
    "                    eachline= ' '.join(stem_words)\n",
    "                else:\n",
    "                    eachline = ' '.join(filtered_stop)\n",
    "            else:\n",
    "                if (stemming == True):\n",
    "                    stem_words = sentences\n",
    "                    stem_words  = [stemmer.stem(w) for w in stem_words]\n",
    "                    eachline= ' '.join(stem_words)\n",
    "                else:\n",
    "                    eachline= each\n",
    "            eachline = [eachline]\n",
    "            output.extend(eachline)\n",
    "    # print(output)\n",
    "    output_string = \" \".join(output)\n",
    "    return  output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store tokenizing data into \".txt\" file\n",
    "def create_db(data, filename):\n",
    "    if (os.getcwd() != \"/Users/astridz/Documents/Moho_Bot/Documents\"):\n",
    "        os.chdir('Documents')\n",
    "        \n",
    "    data_string = data[0].page_content\n",
    "    data_string = data_string.replace(\"\\n\", \"\")\n",
    "    clean_data = preprocessing(data_string, True, False)\n",
    "    \n",
    "    writing(clean_data, filename)\n",
    "    os.chdir('../')\n",
    "    AssertionError(os.getcwd() != \"/Users/astridz/Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cs_page.txt\"\n",
    "create_db(cs_data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding**: split the document, embed the chunks, and store them into Epsilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Epsilla\n",
    "from pyepsilla import vectordb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from typing import List\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEmbeddings():\n",
    "  def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "    return model.encode(texts).tolist()\n",
    "  \n",
    "embeddings = LocalEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to localhost:8888 successfully.\n",
      "[INFO] Connected to localhost:8888 successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get list of all files in \"./documents/\"\n",
    "files = glob(\"./documents/*\")\n",
    "\n",
    "for file in files:\n",
    "  loader = TextLoader(file)\n",
    "  documents = loader.load()\n",
    "  splitted_documents = CharacterTextSplitter(\n",
    "    separator='\\n', chunk_size=1000, \n",
    "    chunk_overlap=200).split_documents(documents)\n",
    "\n",
    "  client = vectordb.Client()\n",
    "  \n",
    "  # Connect to Epsilla as knowledge base.\n",
    "  vector_store = Epsilla.from_documents(\n",
    "    splitted_documents,\n",
    "    embeddings,\n",
    "    client,\n",
    "    db_path=\"/tmp/localchatdb\",\n",
    "    db_name=\"LocalChatDB\",\n",
    "    collection_name=\"LocalChatCollection\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Llama with llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model name is  llama-2-7b-chat.Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "# Download the model file\n",
    "model_name = 'TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf'\n",
    "pure_name = model_name.split('/')[-1]\n",
    "parts = model_name.split('/')\n",
    "model_path = f\"{parts[0]}/{parts[1]}\"\n",
    "print(\"Your model name is \", pure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama.cpp has already been cloned into this directory!\n",
      "/Users/astridz/Documents/Moho_Bot\n",
      "current directory is  /Users/astridz/Documents/Moho_Bot\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/astridz/Documents')\n",
    "if not os.path.exists('llama.cpp'):\n",
    "    print(\"Cloning llama.cpp...\")\n",
    "    !git clone https://github.com/ggerganov/llama.cpp\n",
    "    %cd llama.cpp\n",
    "    print(\"Compiling for Mac with M1 chip...\")\n",
    "    !LLAMA_METAL=1 make\n",
    "    print(\"Compilation completed!\")\n",
    "    %cd ../\n",
    "    %cd Moho.Bot\n",
    "else:\n",
    "    print(\"llama.cpp has already been cloned into this directory!\")\n",
    "    %cd MOHO_BOT\n",
    "print(\"current directory is \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-2-7b-chat.Q4_K_M.gguf already exists!\n",
      "/Users/astridz/Documents/Moho_Bot\n"
     ]
    }
   ],
   "source": [
    "# set directory to llama.cpp\n",
    "os.chdir('/Users/astridz/Documents/llama.cpp/')\n",
    "if not os.path.exists(pure_name):\n",
    "    !wget https://huggingface.co/{model_name}\n",
    "else:\n",
    "    print(f\"{pure_name} already exists!\")\n",
    "%cd ../Moho_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 16:11:37.696 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# Check if 'key' already exists in session_state\n",
    "# If not, then initialize it\n",
    "if 'key' not in st.session_state:\n",
    "    st.session_state['key'] = 'value'\n",
    "\n",
    "# Session State also supports the attribute based syntax\n",
    "if 'key' not in st.session_state:\n",
    "    st.session_state.key = 'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./main -m llama-2-7b-chat.Q4_K_M.gguf -c 1024 -ngl 48 \n",
      "    Answer the Question based on the given Context. Try to understand the Context and rephrase them.\n",
      "    Please don't make things up or say things not mentioned in the Context. Ask for more information when needed.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Testing: Connect to Llama\n",
    "model_name = 'TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf'\n",
    "pure_name = model_name.split('/')[-1]\n",
    "parts = model_name.split('/')\n",
    "model_path = f\"{parts[0]}/{parts[1]}\"\n",
    "\n",
    "prompt = f'''\n",
    "    Answer the Question based on the given Context. Try to understand the Context and rephrase them.\n",
    "    Please don't make things up or say things not mentioned in the Context. Ask for more information when needed.\n",
    "    '''\n",
    "    \n",
    "# WaitReview: call model\n",
    "os.chdir('/Users/astridz/Documents/llama.cpp')\n",
    "# command = ./main -m llama-2-7b-chat.Q4_K_M.gguf  -n 1024 -ngl 48\n",
    "# command = ['./main', '-m', pure_name, '-ngl 48', prompt]\n",
    "# ./main -m ./models/7B/ggml-model-q4_0.bin -n 1024 --repeat_penalty 1.0 --color -i -r \"User:\" -f ./prompts/chat-with-bob.txt\n",
    "command = f\"./main -m {pure_name} -c 1024 -ngl 48 {prompt}\"\n",
    "f\"./main -m {pure_name} -c 1024 -ngl 48 {prompt}\"\n",
    "print(command)\n",
    "process = subprocess.Popen(command, shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "# out, err = process.communicate()\n",
    "\n",
    "# if err:\n",
    "#     print(\"error occurred: \",err.decode())\n",
    "output = process.stdout.read()\n",
    "content = ''\n",
    "if output:\n",
    "    content = content + output\n",
    "return_code = process.poll()\n",
    "\n",
    "# Change back to the parent directory using Python\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a QA Chain using Llama2:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
